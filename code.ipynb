{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826b54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d6e9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, value, type, line):\n",
    "        self.value = value\n",
    "        self.type = type\n",
    "        self.line = line\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Token({self.type}, '{self.value}', line {self.line})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33683311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self, source_code):\n",
    "        self.source_code = source_code\n",
    "        self.tokens = []\n",
    "\n",
    "    def tokenize(self):\n",
    "        token_specification = [\n",
    "            (\"FUNCTION\", r'fn'),\n",
    "            (\"MAIN\", r'main'),\n",
    "            (\"LET\", r'let'),\n",
    "            (\"INT\", r'int'),\n",
    "            (\"CHAR\", r'char'),\n",
    "            (\"FLOAT\", r'float'),\n",
    "            (\"IF\", r'if'),\n",
    "            (\"ELSE\", r'else'),\n",
    "            (\"WHILE\", r'while'),\n",
    "            (\"PRINTLN\", r'println'),\n",
    "            (\"RETURN\", r'return'),\n",
    "            (\"LBRACKET\", r'\\('),\n",
    "            (\"RBRACKET\", r'\\)'),\n",
    "            (\"LBRACE\", r'\\{'),\n",
    "            (\"RBRACE\", r'\\}'),\n",
    "            (\"ARROW\", r'->'),\n",
    "            (\"COLON\", r':'),\n",
    "            (\"SEMICOLON\", r';'),\n",
    "            (\"COMMA\", r','),\n",
    "            (\"EQ\", r'=='),\n",
    "            (\"NE\", r'!='),\n",
    "            (\"GE\", r'>='),\n",
    "            (\"LE\", r'<='),\n",
    "            (\"GT\", r'>'),\n",
    "            (\"LT\", r'<'),\n",
    "            (\"ASSIGN\", r'='),\n",
    "            (\"PLUS\", r'\\+'),\n",
    "            (\"MINUS\", r'-'),\n",
    "            (\"MULT\", r'\\*'),\n",
    "            (\"DIV\", r'/'),\n",
    "            (\"FLOAT_CONST\", r'[0-9]+\\.[0-9]+'),\n",
    "            (\"INT_CONST\", r'[0-9]+'),\n",
    "            (\"CHAR_LITERAL\", r\"'[^']'\"),\n",
    "            (\"FMT_STRING\", r'\"([^\"\\\\]|\\\\.)*\"'),\n",
    "            (\"ID\", r'[a-zA-Z]([a-zA-Z0-9_])*'),\n",
    "            (\"SKIP\", r'[ \\t\\n]+'),\n",
    "            (\"MISMATCH\", r'.')\n",
    "        ]\n",
    "\n",
    "        tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
    "        line_num = 1\n",
    "        line_start = 0\n",
    "        \n",
    "        for mo in re.finditer(tok_regex, self.source_code):\n",
    "            kind = mo.lastgroup\n",
    "            value = mo.group()\n",
    "            column = mo.start() - line_start\n",
    "            \n",
    "            if kind == \"SKIP\":\n",
    "                line_num += value.count('\\n')\n",
    "                if '\\n' in value:\n",
    "                    line_start = mo.end() - len(value) + value.rfind('\\n') + 1\n",
    "                continue\n",
    "            elif kind == \"MISMATCH\":\n",
    "                raise RuntimeError(f'Unexpected character {value!r} at line {line_num}')\n",
    "            else:\n",
    "                self.tokens.append(Token(value, kind, line_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5e894f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'codigo_p.txt' loaded successfully!\n",
      "\n",
      "Tokens found:\n",
      "Token(FUNCTION, 'fn', line 1)\n",
      "Token(ID, 'soma', line 1)\n",
      "Token(LBRACKET, '(', line 1)\n",
      "Token(ID, 'x', line 1)\n",
      "Token(COLON, ':', line 1)\n",
      "Token(INT, 'int', line 1)\n",
      "Token(COMMA, ',', line 1)\n",
      "Token(ID, 'y', line 1)\n",
      "Token(COLON, ':', line 1)\n",
      "Token(INT, 'int', line 1)\n",
      "Token(RBRACKET, ')', line 1)\n",
      "Token(ARROW, '->', line 1)\n",
      "Token(INT, 'int', line 1)\n",
      "Token(LBRACE, '{', line 1)\n",
      "Token(RETURN, 'return', line 2)\n",
      "Token(ID, 'x', line 2)\n",
      "Token(PLUS, '+', line 2)\n",
      "Token(ID, 'y', line 2)\n",
      "Token(SEMICOLON, ';', line 2)\n",
      "Token(RBRACE, '}', line 3)\n",
      "Token(FUNCTION, 'fn', line 4)\n",
      "Token(MAIN, 'main', line 4)\n",
      "Token(LBRACKET, '(', line 4)\n",
      "Token(RBRACKET, ')', line 4)\n",
      "Token(LBRACE, '{', line 4)\n",
      "Token(LET, 'let', line 5)\n",
      "Token(ID, 'a', line 5)\n",
      "Token(COMMA, ',', line 5)\n",
      "Token(ID, 'b', line 5)\n",
      "Token(COMMA, ',', line 5)\n",
      "Token(ID, 'c', line 5)\n",
      "Token(COLON, ':', line 5)\n",
      "Token(INT, 'int', line 5)\n",
      "Token(SEMICOLON, ';', line 5)\n",
      "Token(ID, 'b', line 6)\n",
      "Token(ASSIGN, '=', line 6)\n",
      "Token(INT_CONST, '40', line 6)\n",
      "Token(SEMICOLON, ';', line 6)\n",
      "Token(ID, 'c', line 7)\n",
      "Token(ASSIGN, '=', line 7)\n",
      "Token(INT_CONST, '39', line 7)\n",
      "Token(SEMICOLON, ';', line 7)\n",
      "Token(ID, 'a', line 8)\n",
      "Token(ASSIGN, '=', line 8)\n",
      "Token(ID, 'soma', line 8)\n",
      "Token(LBRACKET, '(', line 8)\n",
      "Token(ID, 'b', line 8)\n",
      "Token(COMMA, ',', line 8)\n",
      "Token(ID, 'c', line 8)\n",
      "Token(RBRACKET, ')', line 8)\n",
      "Token(SEMICOLON, ';', line 8)\n",
      "Token(PRINTLN, 'println', line 9)\n",
      "Token(LBRACKET, '(', line 9)\n",
      "Token(FMT_STRING, '\"valor = %d\"', line 9)\n",
      "Token(COMMA, ',', line 9)\n",
      "Token(ID, 'a', line 9)\n",
      "Token(RBRACKET, ')', line 9)\n",
      "Token(SEMICOLON, ';', line 9)\n",
      "Token(RBRACE, '}', line 10)\n",
      "Token(FUNCTION, 'fn', line 12)\n",
      "Token(ID, 'calculadora', line 12)\n",
      "Token(LBRACKET, '(', line 12)\n",
      "Token(ID, 'op', line 12)\n",
      "Token(COLON, ':', line 12)\n",
      "Token(CHAR, 'char', line 12)\n",
      "Token(COMMA, ',', line 12)\n",
      "Token(ID, 'x', line 12)\n",
      "Token(COLON, ':', line 12)\n",
      "Token(FLOAT, 'float', line 12)\n",
      "Token(COMMA, ',', line 12)\n",
      "Token(ID, 'y', line 12)\n",
      "Token(COLON, ':', line 12)\n",
      "Token(FLOAT, 'float', line 12)\n",
      "Token(RBRACKET, ')', line 12)\n",
      "Token(ARROW, '->', line 12)\n",
      "Token(FLOAT, 'float', line 12)\n",
      "Token(LBRACE, '{', line 12)\n",
      "Token(IF, 'if', line 13)\n",
      "Token(ID, 'op', line 13)\n",
      "Token(EQ, '==', line 13)\n",
      "Token(CHAR_LITERAL, ''+'', line 13)\n",
      "Token(LBRACE, '{', line 13)\n",
      "Token(RETURN, 'return', line 14)\n",
      "Token(ID, 'x', line 14)\n",
      "Token(PLUS, '+', line 14)\n",
      "Token(ID, 'y', line 14)\n",
      "Token(SEMICOLON, ';', line 14)\n",
      "Token(RBRACE, '}', line 15)\n",
      "Token(ELSE, 'else', line 16)\n",
      "Token(IF, 'if', line 16)\n",
      "Token(ID, 'op', line 16)\n",
      "Token(EQ, '==', line 16)\n",
      "Token(CHAR_LITERAL, ''-'', line 16)\n",
      "Token(LBRACE, '{', line 16)\n",
      "Token(RETURN, 'return', line 17)\n",
      "Token(ID, 'x', line 17)\n",
      "Token(MINUS, '-', line 17)\n",
      "Token(ID, 'y', line 17)\n",
      "Token(SEMICOLON, ';', line 17)\n",
      "Token(RBRACE, '}', line 18)\n",
      "Token(ELSE, 'else', line 19)\n",
      "Token(IF, 'if', line 19)\n",
      "Token(ID, 'op', line 19)\n",
      "Token(EQ, '==', line 19)\n",
      "Token(CHAR_LITERAL, ''*'', line 19)\n",
      "Token(LBRACE, '{', line 19)\n",
      "Token(RETURN, 'return', line 20)\n",
      "Token(ID, 'x', line 20)\n",
      "Token(MULT, '*', line 20)\n",
      "Token(ID, 'y', line 20)\n",
      "Token(SEMICOLON, ';', line 20)\n",
      "Token(RBRACE, '}', line 21)\n",
      "Token(ELSE, 'else', line 22)\n",
      "Token(IF, 'if', line 22)\n",
      "Token(ID, 'op', line 22)\n",
      "Token(EQ, '==', line 22)\n",
      "Token(CHAR_LITERAL, ''/'', line 22)\n",
      "Token(LBRACE, '{', line 22)\n",
      "Token(IF, 'if', line 23)\n",
      "Token(ID, 'y', line 23)\n",
      "Token(EQ, '==', line 23)\n",
      "Token(FLOAT_CONST, '0.0', line 23)\n",
      "Token(LBRACE, '{', line 23)\n",
      "Token(RETURN, 'return', line 24)\n",
      "Token(FLOAT_CONST, '0.0', line 24)\n",
      "Token(SEMICOLON, ';', line 24)\n",
      "Token(RBRACE, '}', line 25)\n",
      "Token(RETURN, 'return', line 26)\n",
      "Token(ID, 'x', line 26)\n",
      "Token(DIV, '/', line 26)\n",
      "Token(ID, 'y', line 26)\n",
      "Token(SEMICOLON, ';', line 26)\n",
      "Token(RBRACE, '}', line 27)\n",
      "Token(RETURN, 'return', line 28)\n",
      "Token(FLOAT_CONST, '0.0', line 28)\n",
      "Token(SEMICOLON, ';', line 28)\n",
      "Token(RBRACE, '}', line 29)\n",
      "Token(FUNCTION, 'fn', line 30)\n",
      "Token(MAIN, 'main', line 30)\n",
      "Token(LBRACKET, '(', line 30)\n",
      "Token(RBRACKET, ')', line 30)\n",
      "Token(LBRACE, '{', line 30)\n",
      "Token(LET, 'let', line 31)\n",
      "Token(ID, 'a', line 31)\n",
      "Token(COMMA, ',', line 31)\n",
      "Token(ID, 'b', line 31)\n",
      "Token(COLON, ':', line 31)\n",
      "Token(FLOAT, 'float', line 31)\n",
      "Token(SEMICOLON, ';', line 31)\n",
      "Token(ID, 'a', line 32)\n",
      "Token(ASSIGN, '=', line 32)\n",
      "Token(FLOAT_CONST, '1.8', line 32)\n",
      "Token(SEMICOLON, ';', line 32)\n",
      "Token(ID, 'b', line 33)\n",
      "Token(ASSIGN, '=', line 33)\n",
      "Token(FLOAT_CONST, '7.2', line 33)\n",
      "Token(SEMICOLON, ';', line 33)\n",
      "Token(PRINTLN, 'println', line 34)\n",
      "Token(LBRACKET, '(', line 34)\n",
      "Token(FMT_STRING, '\"%f\"', line 34)\n",
      "Token(COMMA, ',', line 34)\n",
      "Token(ID, 'calculadora', line 34)\n",
      "Token(LBRACKET, '(', line 34)\n",
      "Token(CHAR_LITERAL, ''*'', line 34)\n",
      "Token(COMMA, ',', line 34)\n",
      "Token(ID, 'a', line 34)\n",
      "Token(COMMA, ',', line 34)\n",
      "Token(ID, 'b', line 34)\n",
      "Token(RBRACKET, ')', line 34)\n",
      "Token(RBRACKET, ')', line 34)\n",
      "Token(SEMICOLON, ';', line 34)\n",
      "Token(RBRACE, '}', line 35)\n",
      "Token(FUNCTION, 'fn', line 37)\n",
      "Token(MAIN, 'main', line 37)\n",
      "Token(LBRACKET, '(', line 37)\n",
      "Token(RBRACKET, ')', line 37)\n",
      "Token(LBRACE, '{', line 37)\n",
      "Token(LET, 'let', line 38)\n",
      "Token(ID, 'i', line 38)\n",
      "Token(COLON, ':', line 38)\n",
      "Token(INT, 'int', line 38)\n",
      "Token(SEMICOLON, ';', line 38)\n",
      "Token(ID, 'i', line 39)\n",
      "Token(ASSIGN, '=', line 39)\n",
      "Token(INT_CONST, '0', line 39)\n",
      "Token(SEMICOLON, ';', line 39)\n",
      "Token(WHILE, 'while', line 40)\n",
      "Token(ID, 'i', line 40)\n",
      "Token(LT, '<', line 40)\n",
      "Token(INT_CONST, '10', line 40)\n",
      "Token(LBRACE, '{', line 40)\n",
      "Token(PRINTLN, 'println', line 41)\n",
      "Token(LBRACKET, '(', line 41)\n",
      "Token(FMT_STRING, '\"%d\"', line 41)\n",
      "Token(COMMA, ',', line 41)\n",
      "Token(ID, 'i', line 41)\n",
      "Token(RBRACKET, ')', line 41)\n",
      "Token(SEMICOLON, ';', line 41)\n",
      "Token(ID, 'i', line 42)\n",
      "Token(ASSIGN, '=', line 42)\n",
      "Token(ID, 'i', line 42)\n",
      "Token(PLUS, '+', line 42)\n",
      "Token(INT_CONST, '1', line 42)\n",
      "Token(SEMICOLON, ';', line 42)\n",
      "Token(RBRACE, '}', line 43)\n",
      "Token(RBRACE, '}', line 44)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        with open(\"codigo_p.txt\", \"r\") as f:\n",
    "            source_code = f.read()\n",
    "        print(\"File 'codigo_p.txt' loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File 'codigo_p.txt' not found.\")\n",
    "    lexer = Lexer(source_code)\n",
    "    lexer.tokenize()\n",
    "\n",
    "    print(\"\\nTokens found:\")\n",
    "    for token in lexer.tokens:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7e5d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens\n",
    "        self.pos = 0\n",
    "\n",
    "    def current_token(self):\n",
    "        if self.pos < len(self.tokens):\n",
    "            return self.tokens[self.pos]\n",
    "        return (\"EOF\", None)\n",
    "\n",
    "    def eat(self, token_type):\n",
    "        if self.current_token()[0] == token_type:\n",
    "            self.pos += 1\n",
    "        else:\n",
    "            raise RuntimeError(f'Unexpected token: {self.current_token()}, expected: {token_type}')\n",
    "\n",
    "    def parse_var_decl(self):\n",
    "        self.eat(\"LET\")\n",
    "        self.parse_var_list()\n",
    "        self.eat(\"COLON\")\n",
    "        if self.current_token()[0] in (\"INT\", \"CHAR\", \"FLOAT\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "        else:\n",
    "            raise RuntimeError(f'Unexpected type: {self.current_token()}')\n",
    "        self.eat(\"SEMICOLON\")\n",
    "\n",
    "    def parse_var_list(self):\n",
    "        self.eat(\"ID\")\n",
    "        while self.current_token()[0] == \"COMMA\":\n",
    "            self.eat(\"COMMA\")\n",
    "            self.eat(\"ID\")\n",
    "\n",
    "    def parse_function(self):\n",
    "        self.eat(\"FUNCTION\")\n",
    "        if self.current_token()[0] in (\"ID\", \"MAIN\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Expected function name, got: {self.current_token()}\")\n",
    "        self.eat(\"LBRACKET\")\n",
    "        self.parse_param_list()\n",
    "        self.eat(\"RBRACKET\")\n",
    "        if self.current_token()[0] == \"ARROW\":\n",
    "            self.eat(\"ARROW\")\n",
    "            if self.current_token()[0] in (\"INT\", \"FLOAT\", \"CHAR\"):\n",
    "                self.eat(self.current_token()[0])\n",
    "            else:\n",
    "                raise RuntimeError(\"Invalid return type\")\n",
    "        self.eat(\"LBRACE\")\n",
    "        while self.current_token()[0] != \"RBRACE\":\n",
    "            self.parse_statement()\n",
    "        self.eat(\"RBRACE\")\n",
    "\n",
    "    def parse_param_list(self):\n",
    "        if self.current_token()[0] == \"ID\":\n",
    "            self.eat(\"ID\")\n",
    "            self.eat(\"COLON\")\n",
    "            if self.current_token()[0] in (\"INT\", \"FLOAT\", \"CHAR\"):\n",
    "                self.eat(self.current_token()[0])\n",
    "            else:\n",
    "                raise RuntimeError(f\"Invalid parameter type: {self.current_token()}\")\n",
    "            while self.current_token()[0] == \"COMMA\":\n",
    "                self.eat(\"COMMA\")\n",
    "                self.eat(\"ID\")\n",
    "                self.eat(\"COLON\")\n",
    "                if self.current_token()[0] in (\"INT\", \"FLOAT\", \"CHAR\"):\n",
    "                    self.eat(self.current_token()[0])\n",
    "                else:\n",
    "                    raise RuntimeError(f\"Invalid parameter type: {self.current_token()}\")\n",
    "\n",
    "    def parse_func_call(self, expect_semicolon=True):\n",
    "        self.eat(\"ID\")\n",
    "        self.eat(\"LBRACKET\")\n",
    "        self.parse_args_list()\n",
    "        self.eat(\"RBRACKET\")\n",
    "        if expect_semicolon and self.current_token()[0] == \"SEMICOLON\":\n",
    "            self.eat(\"SEMICOLON\")\n",
    "\n",
    "    def parse_statement(self):\n",
    "        token_type = self.current_token()[0]\n",
    "        if token_type == \"LET\":\n",
    "            self.parse_var_decl()\n",
    "        elif token_type == \"RETURN\":\n",
    "            self.eat(\"RETURN\")\n",
    "            self.parse_expression()\n",
    "            self.eat(\"SEMICOLON\")\n",
    "        elif token_type == \"PRINTLN\":\n",
    "            self.eat(\"PRINTLN\")\n",
    "            self.eat(\"LBRACKET\")\n",
    "            if self.current_token()[0] == \"FMT_STRING\":\n",
    "                self.eat(\"FMT_STRING\")\n",
    "                if self.current_token()[0] == \"COMMA\":\n",
    "                    self.eat(\"COMMA\")\n",
    "                    self.parse_args_list()\n",
    "            self.eat(\"RBRACKET\")\n",
    "            self.eat(\"SEMICOLON\")\n",
    "        elif token_type == \"IF\":\n",
    "            self.parse_if()\n",
    "        elif token_type == \"WHILE\":\n",
    "            self.parse_while()\n",
    "        elif token_type == \"ID\":\n",
    "            if self.pos + 1 < len(self.tokens):\n",
    "                next_token = self.tokens[self.pos + 1][0]\n",
    "                if next_token == \"ASSIGN\":\n",
    "                    self.parse_assignment()\n",
    "                elif next_token == \"LBRACKET\":\n",
    "                    self.parse_func_call(expect_semicolon=True)\n",
    "                else:\n",
    "                    self.pos += 1\n",
    "            else:\n",
    "                self.pos += 1\n",
    "        else:\n",
    "            self.pos += 1\n",
    "\n",
    "    # Exemplo de parsing de expressão com precedência (simplificado)\n",
    "    def parse_expression(self):\n",
    "        self.parse_rel()\n",
    "        while self.current_token()[0] in (\"EQ\", \"NE\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "            self.parse_rel()\n",
    "\n",
    "    def parse_rel(self):\n",
    "        self.parse_add()\n",
    "        while self.current_token()[0] in (\"LT\", \"LE\", \"GT\", \"GE\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "            self.parse_add()\n",
    "\n",
    "    def parse_add(self):\n",
    "        self.parse_term()\n",
    "        while self.current_token()[0] in (\"PLUS\", \"MINUS\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "            self.parse_term()\n",
    "\n",
    "    def parse_term(self):\n",
    "        self.parse_factor()\n",
    "        while self.current_token()[0] in (\"MULT\", \"DIV\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "            self.parse_factor()\n",
    "\n",
    "    def parse_factor(self):\n",
    "        token_type = self.current_token()[0]\n",
    "        if token_type == \"ID\":\n",
    "            self.eat(\"ID\")\n",
    "            if self.current_token()[0] == \"LBRACKET\":\n",
    "                self.parse_func_call(expect_semicolon=False)\n",
    "        elif token_type in (\"INT_CONST\", \"FLOAT_CONST\", \"CHAR_LITERAL\"):\n",
    "            self.eat(token_type)\n",
    "        elif token_type == \"LBRACKET\":\n",
    "            self.eat(\"LBRACKET\")\n",
    "            self.parse_expression()\n",
    "            self.eat(\"RBRACKET\")\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unexpected token in factor: {self.current_token()}\")\n",
    "\n",
    "    def parse_assignment(self):\n",
    "        self.eat(\"ID\")\n",
    "        self.eat(\"ASSIGN\")\n",
    "        self.parse_expression()\n",
    "        self.eat(\"SEMICOLON\")\n",
    "\n",
    "    def parse_args_list(self):\n",
    "        if self.current_token()[0] in (\"ID\", \"INT_CONST\", \"FLOAT_CONST\", \"CHAR_LITERAL\"):\n",
    "            self.parse_arg()\n",
    "            while self.current_token()[0] == \"COMMA\":\n",
    "                self.eat(\"COMMA\")\n",
    "                self.parse_arg()\n",
    "\n",
    "    def parse_arg(self):\n",
    "        if self.current_token()[0] == \"ID\":\n",
    "            self.eat(\"ID\")\n",
    "            if self.current_token()[0] == \"LBRACKET\":\n",
    "                self.parse_func_call(expect_semicolon=False)\n",
    "        elif self.current_token()[0] in (\"INT_CONST\", \"FLOAT_CONST\", \"CHAR_LITERAL\"):\n",
    "            self.eat(self.current_token()[0])\n",
    "        else:\n",
    "            raise RuntimeError(f\"Invalid argument: {self.current_token()}\")\n",
    "\n",
    "    def parse_if(self):\n",
    "        self.eat(\"IF\")\n",
    "        self.eat(\"LBRACKET\")\n",
    "        self.parse_expression()\n",
    "        self.eat(\"RBRACKET\")\n",
    "        self.eat(\"LBRACE\")\n",
    "        while self.current_token()[0] != \"RBRACE\":\n",
    "            self.parse_statement()\n",
    "        self.eat(\"RBRACE\")\n",
    "        if self.current_token()[0] == \"ELSE\":\n",
    "            self.eat(\"ELSE\")\n",
    "            self.eat(\"LBRACE\")\n",
    "            while self.current_token()[0] != \"RBRACE\":\n",
    "                self.parse_statement()\n",
    "            self.eat(\"RBRACE\")\n",
    "\n",
    "    def parse_while(self):\n",
    "        self.eat(\"WHILE\")\n",
    "        self.eat(\"LBRACKET\")\n",
    "        self.parse_expression()\n",
    "        self.eat(\"RBRACKET\")\n",
    "        self.eat(\"LBRACE\")\n",
    "        while self.current_token()[0] != \"RBRACE\":\n",
    "            self.parse_statement()\n",
    "        self.eat(\"RBRACE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
